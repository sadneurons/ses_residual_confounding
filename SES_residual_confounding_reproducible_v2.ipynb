{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulation of Residual Confounding by SES — Reproducible Research (v2)\n",
    "\n",
    "This notebook is parameterized for **papermill**, includes **inline unit tests**, and outputs a compact **Results** section and styled figures.\n",
    "\n",
    "**Parts**\n",
    "1) **Simulation study** (DAG-informed).  \n",
    "2) **NHANES scaffold** (skips gracefully without XPTs).\n",
    "\n",
    "Artifacts are written to `artifacts/`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "\n",
    "# These parameters can be overridden by papermill\n",
    "N_POP = 120_000\n",
    "SEED = 123\n",
    "ART_DIR = \"artifacts\"\n",
    "NHANES_BASE_DIR = \"\"   # e.g., \"/path/to/nhanes_xpt\"\n",
    "NHANES_CYCLES   = [\"C\",\"D\",\"E\",\"F\",\"G\",\"H\",\"I\",\"J\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os, sys, json, platform, numpy as np, pandas as pd\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "os.makedirs(ART_DIR, exist_ok=True)\n",
    "print(\"Artifacts dir:\", os.path.abspath(ART_DIR))\n",
    "print(\"Timestamp:\", datetime.utcnow().isoformat()+\"Z\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part A — Simulation code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"\n",
    "SES Simulation Scaffold (Python)\n",
    "================================\n",
    "\n",
    "A comprehensive simulation framework for studying socioeconomic status (SES) effects on health\n",
    "outcomes through complex, non-linear causal pathways with selection bias and measurement error.\n",
    "\n",
    "Overview\n",
    "--------\n",
    "This module implements a sophisticated data generating mechanism that simulates realistic\n",
    "relationships between socioeconomic status and disease outcomes, incorporating:\n",
    "\n",
    "1. **Non-linear SES effects**: Complex relationships between true SES and health mediators\n",
    "2. **Selection bias**: Biobank-like participation patterns that create systematic sampling bias\n",
    "3. **Measurement error**: Noisy observation of true SES, mimicking real-world data limitations\n",
    "4. **Multiple analytical approaches**: Comparison of traditional vs. modern causal inference methods\n",
    "\n",
    "Key Features\n",
    "------------\n",
    "- **Realistic Data Generation**: Simulates population-level data with complex causal relationships\n",
    "- **Selection Mechanisms**: Models biobank participation bias based on health and socioeconomic factors\n",
    "- **Multiple SES Representations**: True latent SES*, observed noisy SES, and categorical quintiles\n",
    "- **Flexible Modeling**: Supports linear models, splines, and g-computation for causal inference\n",
    "- **Performance Metrics**: Multiple R² variants and Shapley value decomposition for model comparison\n",
    "\n",
    "Analytical Approaches Compared\n",
    "------------------------------\n",
    "A) **Traditional Mis-specified Models**:\n",
    "   - Linear SES effects using categorical quintiles\n",
    "   - Over-adjusted models including mediators (collider bias)\n",
    "\n",
    "B) **Flexible Spline Models**:\n",
    "   - Non-parametric modeling of SES-outcome relationships\n",
    "   - Comparison between oracle (SES*) and proxy (SES_obs) versions\n",
    "\n",
    "C) **G-computation Dose-Response**:\n",
    "   - Causal intervention curves: E[Y | do(SES = a)]\n",
    "   - Oracle estimates using true SES* vs. proxy estimates using observed SES\n",
    "\n",
    "Mathematical Framework\n",
    "----------------------\n",
    "The data generating process follows this causal structure:\n",
    "    C (confounders) → SES* → M (mediators) → Y (outcome)\n",
    "                  ↓                        ↓\n",
    "               SES_obs                      S (selection)\n",
    "\n",
    "Where:\n",
    "- C: Baseline confounders (age, sex, genetic PCs)\n",
    "- SES*: True latent socioeconomic status\n",
    "- SES_obs: Observed SES proxy with measurement error\n",
    "- M: Health-related mediators (BMI, smoking, blood pressure)\n",
    "- Y: Binary disease outcome\n",
    "- S: Biobank participation (selection indicator)\n",
    "\n",
    "Usage Example\n",
    "-------------\n",
    ">>> # Basic simulation run\n",
    ">>> results, pop, biobank, *curves = run_demo(n_pop=50000, seed=123)\n",
    ">>> print(f\"Population size: {results['n_population']}\")\n",
    ">>> print(f\"Biobank sample: {results['n_biobank']}\")\n",
    ">>> print(f\"True causal R²: {results['causal_R2_true']:.3f}\")\n",
    "\n",
    ">>> # Custom parameters\n",
    ">>> params = DGMParams(n=100000, seed=456, ses_me_sd=0.5)\n",
    ">>> pop_data = simulate_population(params)\n",
    ">>> biobank_data = sample_biobank(pop_data)\n",
    "\n",
    "Dependencies\n",
    "------------\n",
    "- numpy: Numerical computations and random number generation\n",
    "- pandas: Data manipulation and analysis\n",
    "- statsmodels: Statistical modeling and GLM fitting\n",
    "- patsy: Formula interface for statistical models (splines)\n",
    "\n",
    "Author\n",
    "------\n",
    "Dr. Ross A. Dunne\n",
    "\n",
    "Notes\n",
    "-----\n",
    "This simulation is designed for methodological research comparing different approaches\n",
    "to estimating socioeconomic effects on health outcomes in the presence of selection bias\n",
    "and measurement error. The default parameters are calibrated to produce realistic effect\n",
    "sizes and prevalence rates typical of epidemiological studies.\n",
    "\"\"\"\n",
    "\n",
    "from dataclasses import dataclass\n",
    "from typing import Tuple, Dict, List, Optional, Union, Any\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from patsy import dmatrix\n",
    "\n",
    "# -----------------\n",
    "# Helper functions\n",
    "# -----------------\n",
    "\n",
    "def logistic(x: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Compute the logistic (sigmoid) function.\n",
    "\n",
    "    Transforms real-valued inputs to probabilities in (0, 1) using the logistic function:\n",
    "    σ(x) = 1 / (1 + exp(-x))\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    x : array-like\n",
    "        Input values to transform. Can be scalar, vector, or array.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    np.ndarray\n",
    "        Logistic transformation of input, bounded in (0, 1).\n",
    "\n",
    "    Examples\n",
    "    --------\n",
    "    >>> logistic(0)\n",
    "    0.5\n",
    "    >>> logistic(np.array([-2, 0, 2]))\n",
    "    array([0.119, 0.5, 0.881])\n",
    "    \"\"\"\n",
    "    return 1.0 / (1.0 + np.exp(-x))\n",
    "\n",
    "def standardize(x: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Standardize a variable to have mean 0 and standard deviation 1.\n",
    "\n",
    "    Applies z-score normalization: z = (x - μ) / σ\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    x : array-like\n",
    "        Input variable to standardize.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    np.ndarray\n",
    "        Standardized variable with mean ≈ 0 and std ≈ 1.\n",
    "\n",
    "    Examples\n",
    "    --------\n",
    "    >>> x = np.array([1, 2, 3, 4, 5])\n",
    "    >>> z = standardize(x)\n",
    "    >>> np.mean(z), np.std(z)\n",
    "    (0.0, 1.0)\n",
    "    \"\"\"\n",
    "    return (x - np.mean(x)) / np.std(x)\n",
    "\n",
    "def mc_fadden_r2(model_llf: float, null_llf: float) -> float:\n",
    "    \"\"\"\n",
    "    Calculate McFadden's pseudo-R² for logistic regression models.\n",
    "\n",
    "    McFadden's R² is a measure of goodness-of-fit for maximum likelihood models,\n",
    "    analogous to R² in linear regression. It compares the log-likelihood of the\n",
    "    fitted model to that of a null (intercept-only) model.\n",
    "\n",
    "    Formula: R²_McF = 1 - (LL_model / LL_null)\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model_llf : float\n",
    "        Log-likelihood of the fitted model.\n",
    "    null_llf : float\n",
    "        Log-likelihood of the null (intercept-only) model.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        McFadden's pseudo-R², typically between 0 and 1.\n",
    "        Values of 0.2-0.4 are considered excellent fit.\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    Unlike linear R², McFadden's R² does not represent proportion of variance\n",
    "    explained. It measures relative improvement in log-likelihood over the null model.\n",
    "    \"\"\"\n",
    "    return 1 - (model_llf / null_llf)\n",
    "\n",
    "def tjur_r2(y_true: np.ndarray, p_hat: np.ndarray) -> float:\n",
    "    \"\"\"\n",
    "    Calculate Tjur's coefficient of discrimination (R²_D) for binary outcomes.\n",
    "\n",
    "    Tjur's R² measures the difference in mean predicted probabilities between\n",
    "    cases (y=1) and controls (y=0). It provides an intuitive measure of how well\n",
    "    the model discriminates between the two groups.\n",
    "\n",
    "    Formula: R²_D = E[p̂|Y=1] - E[p̂|Y=0]\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    y_true : array-like\n",
    "        True binary outcomes (0 or 1).\n",
    "    p_hat : array-like\n",
    "        Predicted probabilities from the model.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        Tjur's R², ranging from 0 (no discrimination) to 1 (perfect discrimination).\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    Tjur's R² is bounded between 0 and 1 and has a direct interpretation:\n",
    "    it represents the difference in average predicted probability between\n",
    "    positive and negative cases.\n",
    "\n",
    "    References\n",
    "    ----------\n",
    "    Tjur, T. (2009). Coefficients of determination in logistic regression models.\n",
    "    The American Statistician, 63(4), 366-372.\n",
    "    \"\"\"\n",
    "    y_true = np.asarray(y_true)\n",
    "    p_hat = np.asarray(p_hat)\n",
    "    return float(np.mean(p_hat[y_true==1]) - np.mean(p_hat[y_true==0]))\n",
    "\n",
    "def partial_r2_mcfadden(llf_full: float, llf_reduced: float, null_llf: float) -> float:\n",
    "    \"\"\"\n",
    "    Calculate partial (incremental) McFadden's R² for nested model comparison.\n",
    "\n",
    "    Measures the additional explanatory power gained by adding variables to a model,\n",
    "    expressed as the difference in McFadden's R² between the full and reduced models.\n",
    "\n",
    "    Formula: ΔR²_McF = R²_McF(full) - R²_McF(reduced)\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    llf_full : float\n",
    "        Log-likelihood of the full model (with additional variables).\n",
    "    llf_reduced : float\n",
    "        Log-likelihood of the reduced model (baseline).\n",
    "    null_llf : float\n",
    "        Log-likelihood of the null (intercept-only) model.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        Incremental McFadden's R² contributed by the additional variables.\n",
    "        Positive values indicate improvement in model fit.\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    This measure is useful for assessing the contribution of specific variable groups\n",
    "    in nested model comparisons, similar to partial R² in linear regression.\n",
    "    \"\"\"\n",
    "    return mc_fadden_r2(llf_full, null_llf) - mc_fadden_r2(llf_reduced, null_llf)\n",
    "\n",
    "def shapley_two_groups_r2(llf_null: float, llf_g1: float, llf_g2: float, llf_both: float) -> Dict[str, float]:\n",
    "    \"\"\"\n",
    "    Compute Shapley value decomposition of McFadden's R² for two covariate groups.\n",
    "\n",
    "    Applies game-theoretic Shapley values to fairly attribute the total model R²\n",
    "    between two groups of covariates, accounting for their interactions and\n",
    "    order-dependence in contribution calculations.\n",
    "\n",
    "    The Shapley value represents each group's average marginal contribution across\n",
    "    all possible orders of adding groups to the model, providing a fair allocation\n",
    "    of the total explanatory power.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    llf_null : float\n",
    "        Log-likelihood of the null (intercept-only) model.\n",
    "    llf_g1 : float\n",
    "        Log-likelihood of model with group 1 covariates only.\n",
    "    llf_g2 : float  \n",
    "        Log-likelihood of model with group 2 covariates only.\n",
    "    llf_both : float\n",
    "        Log-likelihood of full model with both groups.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Dict[str, float]\n",
    "        Dictionary containing:\n",
    "        - 'G1_share': Shapley value for group 1 (average marginal contribution)\n",
    "        - 'G2_share': Shapley value for group 2 (average marginal contribution)  \n",
    "        - 'R2_total': Total McFadden's R² of the full model\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    For two groups, the Shapley value is the average of marginal contributions\n",
    "    when added first vs. second:\n",
    "\n",
    "    \\u03c6₁ = 0.5 × [(R²₁ - R²₀) + (R²₁₂ - R²₂)]\n",
    "    \\u03c6₂ = 0.5 × [(R²₂ - R²₀) + (R²₁₂ - R²₁)]\n",
    "\n",
    "    Where R²ᵢ denotes McFadden's R² for the model with group i.\n",
    "\n",
    "    Examples\n",
    "    --------\n",
    "    >>> # Example with SES and demographic covariates\n",
    "    >>> shap_results = shapley_two_groups_r2(\n",
    "    ...     llf_null=-1000, llf_g1=-950, llf_g2=-980, llf_both=-920\n",
    "    ... )\n",
    "    >>> print(f\"SES contribution: {shap_results['G1_share']:.3f}\")\n",
    "    >>> print(f\"Demographics contribution: {shap_results['G2_share']:.3f}\")\n",
    "    \"\"\"\n",
    "    r2_null = 0.0\n",
    "    r2_g1 = 1 - (llf_g1 / llf_null)\n",
    "    r2_g2 = 1 - (llf_g2 / llf_null)\n",
    "    r2_both = 1 - (llf_both / llf_null)\n",
    "\n",
    "    # marginal contributions when added first vs second\n",
    "    contrib_g1_first = r2_g1 - r2_null\n",
    "    contrib_g1_second = r2_both - r2_g2\n",
    "    contrib_g2_first = r2_g2 - r2_null\n",
    "    contrib_g2_second = r2_both - r2_g1\n",
    "\n",
    "    return {\n",
    "        \"G1_share\": float(0.5 * (contrib_g1_first + contrib_g1_second)),\n",
    "        \"G2_share\": float(0.5 * (contrib_g2_first + contrib_g2_second)),\n",
    "        \"R2_total\": float(r2_both),\n",
    "    }\n",
    "\n",
    "# -----------------\n",
    "# Data Generating Mechanism\n",
    "# -----------------\n",
    "\n",
    "@dataclass\n",
    "class DGMParams:\n",
    "    \"\"\"\n",
    "    Parameters for the Data Generating Mechanism (DGM) in SES simulation.\n",
    "\n",
    "    This class encapsulates all tunable parameters that control the simulation of\n",
    "    population data, including sample size, selection bias mechanisms, measurement\n",
    "    error specifications, and outcome prevalence calibration.\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    n : int, default=200_000\n",
    "        Total population size for simulation. Larger values provide more stable\n",
    "        estimates but increase computational time. Recommended: 50K-500K.\n",
    "\n",
    "    seed : int, default=42\n",
    "        Random seed for reproducible results across simulation runs.\n",
    "\n",
    "    Selection Bias Parameters\n",
    "    -------------------------\n",
    "    These parameters control biobank participation probability via logistic model:\n",
    "    logit(P(S=1)) = sel_intercept + sel_ses*SES* + sel_smoke*smoke + ...\n",
    "\n",
    "    sel_intercept : float, default=-2.2\n",
    "        Intercept term controlling overall participation rate. More negative values\n",
    "        lead to lower participation rates. Default yields ~5-15% participation.\n",
    "\n",
    "    sel_ses : float, default=0.6\n",
    "        Effect of true SES on participation. Positive values mean higher SES\n",
    "        individuals are more likely to participate (typical in biobanks).\n",
    "\n",
    "    sel_smoke : float, default=-0.8\n",
    "        Effect of smoking on participation. Negative values reflect that smokers\n",
    "        are less likely to participate in health studies.\n",
    "\n",
    "    sel_bmi : float, default=-0.08\n",
    "        Effect of BMI (per unit above 25) on participation. Negative values\n",
    "        indicate that higher BMI reduces participation likelihood.\n",
    "\n",
    "    sel_age : float, default=0.10\n",
    "        Effect of standardized age on participation. Positive values reflect\n",
    "        that older individuals may be more likely to participate.\n",
    "\n",
    "    sel_risk_score : float, default=-0.7\n",
    "        Effect of overall health risk score on participation. Negative values\n",
    "        implement \"healthy volunteer bias\" - healthier individuals more likely\n",
    "        to participate.\n",
    "\n",
    "    Measurement Error Parameters\n",
    "    ----------------------------\n",
    "    ses_me_sd : float, default=0.7\n",
    "        Standard deviation of measurement error in observed SES proxy.\n",
    "        Higher values create more attenuation bias. Typical range: 0.3-1.0.\n",
    "        Formula: SES_obs = 0.8*SES* + N(0, ses_me_sd²)\n",
    "\n",
    "    Outcome Parameters\n",
    "    ------------------\n",
    "    y_intercept : float, default=-4.1\n",
    "        Intercept term in outcome logistic model controlling baseline disease\n",
    "        prevalence. Adjust to achieve desired population prevalence (target: 10-20%).\n",
    "        More negative values reduce prevalence.\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    Default parameters are calibrated to produce realistic epidemiological patterns:\n",
    "    - Participation rates similar to large biobanks (5-15%)\n",
    "    - Healthy volunteer bias and socioeconomic selection\n",
    "    - Moderate measurement error in SES proxy\n",
    "    - Disease prevalence typical of chronic conditions\n",
    "\n",
    "    Examples\n",
    "    --------\n",
    "    >>> # Default parameters\n",
    "    >>> params = DGMParams()\n",
    "    >>> \n",
    "    >>> # High measurement error scenario\n",
    "    >>> params_noisy = DGMParams(ses_me_sd=1.2, n=100_000)\n",
    "    >>> \n",
    "    >>> # Reduced selection bias\n",
    "    >>> params_less_bias = DGMParams(sel_ses=0.2, sel_risk_score=-0.3)\n",
    "    \"\"\"\n",
    "    n: int = 200_000\n",
    "    seed: int = 42\n",
    "\n",
    "    # Selection strength parameters\n",
    "    sel_intercept: float = -2.2   # controls sampling fraction (~5-15% typical for demo)\n",
    "    sel_ses: float = 0.6\n",
    "    sel_smoke: float = -0.8\n",
    "    sel_bmi: float = -0.08  # per unit BMI above 25\n",
    "    sel_age: float = 0.10\n",
    "    sel_risk_score: float = -0.7  # healthier more likely to volunteer\n",
    "\n",
    "    # Measurement error for observed SES proxy\n",
    "    ses_me_sd: float = 0.7\n",
    "\n",
    "    # Outcome base rate calibrator\n",
    "    y_intercept: float = -4.1  # tweak to get ~10-20% prevalence in population\n",
    "\n",
    "def simulate_population(params: DGMParams) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Generate synthetic population data with complex SES-health relationships.\n",
    "\n",
    "    Creates a realistic population dataset incorporating non-linear relationships\n",
    "    between socioeconomic status and health outcomes, with multiple mediating\n",
    "    pathways and selection mechanisms that mirror real-world biobank studies.\n",
    "\n",
    "    The data generating process follows this causal structure:\n",
    "    C (age, sex, PC1) → SES* → M (BMI, smoking, SBP) → Y (disease)\n",
    "                     ↓                              ↓\n",
    "                  SES_obs                            S (selection)\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    params : DGMParams\n",
    "        Configuration object containing all simulation parameters including\n",
    "        sample size, selection mechanisms, and measurement error specifications.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        Simulated population data with columns:\n",
    "        - age: Age in years (40-85, mean≈60)\n",
    "        - sex: Binary sex indicator (0=female, 1=male)\n",
    "        - pc1: First principal component (genetic/ancestry proxy)\n",
    "        - ses_star: True latent SES (standardized)\n",
    "        - ses_obs: Observed SES proxy with measurement error\n",
    "        - ses_quintile: Categorical SES (0-4 quintiles)\n",
    "        - bmi: Body mass index with quadratic SES relationship\n",
    "        - sbp: Systolic blood pressure with saturating SES effect\n",
    "        - smoke: Binary smoking indicator with threshold effect\n",
    "        - y: Binary disease outcome\n",
    "        - s: Binary selection/participation indicator\n",
    "        - p_s: Participation probability\n",
    "        - p_y: Disease probability\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    Key relationships implemented:\n",
    "\n",
    "    1. **SES Generation**: SES* ~ N(0.15*(50-age) + 0.15*sex + 0.25*PC1, 1)\n",
    "    2. **Measurement Error**: SES_obs = 0.8*SES* + N(0, σ²)\n",
    "    3. **BMI (U-shaped)**: BMI ~ 27.5 + 1.2*(SES*-0.2)² + noise\n",
    "    4. **Smoking (threshold)**: Higher rates below SES* = -0.5\n",
    "    5. **Blood Pressure (saturating)**: Improvement plateaus at high SES\n",
    "    6. **Disease**: Direct SES effect plus mediation through risk factors\n",
    "    7. **Selection**: Healthy volunteer bias with SES-dependent participation\n",
    "\n",
    "    The simulation produces realistic epidemiological patterns including:\n",
    "    - Non-linear dose-response relationships\n",
    "    - Measurement error attenuation\n",
    "    - Selection bias favoring healthier, higher-SES participants\n",
    "\n",
    "    Examples\n",
    "    --------\n",
    "    >>> params = DGMParams(n=50000, seed=123)\n",
    "    >>> pop_data = simulate_population(params)\n",
    "    >>> print(f\"Population size: {len(pop_data)}\")\n",
    "    >>> print(f\"Disease prevalence: {pop_data['y'].mean():.1%}\")\n",
    "    >>> print(f\"Participation rate: {pop_data['s'].mean():.1%}\")\n",
    "    \"\"\"\n",
    "    rng = np.random.default_rng(params.seed)\n",
    "    n = params.n\n",
    "\n",
    "    # Baseline covariates C\n",
    "    age = rng.normal(60, 10, n).clip(40, 85)\n",
    "    sex = rng.integers(0, 2, n)  # 0=female, 1=male\n",
    "    pc1 = rng.normal(0, 1, n)\n",
    "\n",
    "    # Latent SES*\n",
    "    ses_star = rng.normal(loc=0.15 * standardize(50 - age) + 0.15*sex + 0.25*pc1, scale=1.0, size=n)\n",
    "\n",
    "    # Observed SES proxy (noisy, then optionally coarsened)\n",
    "    ses_obs = 0.8 * ses_star + rng.normal(0, params.ses_me_sd, n)\n",
    "\n",
    "    # Simple quintiles (coarsened)\n",
    "    q = pd.qcut(ses_obs, 5, labels=False)  # 0..4\n",
    "    ses_quintile = q.astype(int)\n",
    "\n",
    "    # Mediators (non-linear)\n",
    "    # BMI: quadratic (U-ish), lower with mid SES*\n",
    "    bmi = 27.5 + 1.2*(ses_star - 0.2)**2 + 0.05*(age-60) + 0.6*sex + rng.normal(0, 2.5, n)\n",
    "\n",
    "    # Smoking: logistic with threshold and SES*\n",
    "    lp_smoke = -0.5 - 1.2*ses_star + 0.6*(ses_star < -0.5).astype(float) + 0.01*(age-60) + 0.2*sex\n",
    "    p_smoke = logistic(lp_smoke)\n",
    "    smoke = rng.binomial(1, p_smoke, n)\n",
    "\n",
    "    # SBP: saturating improvement with SES*\n",
    "    sbp = 125 - 4*np.log1p(np.exp(ses_star - 0.0)) + 0.12*(age-60) + 3.0*sex + rng.normal(0, 8.0, n)\n",
    "\n",
    "    # Outcome Y (binary disease within timeframe)\n",
    "    # Direct SES* (mild monotone + threshold), plus mediators, plus C\n",
    "    g_ses = 0.25*ses_star + 0.15*(ses_star < -0.8).astype(float)\n",
    "    lp_y = (params.y_intercept + g_ses\n",
    "            + 0.06*(sbp-120) + 0.08*(bmi-25) + 1.0*smoke\n",
    "            + 0.018*(age-60) + 0.12*sex)\n",
    "\n",
    "    p_y = logistic(lp_y)\n",
    "    y = rng.binomial(1, p_y, n)\n",
    "\n",
    "    # Selection S (biobank participation)\n",
    "    # Use an approximate risk score (without intercept) as a driver of selection\n",
    "    risk_score = (g_ses + 0.06*(sbp-120) + 0.08*(bmi-25) + 1.0*smoke + 0.018*(age-60) + 0.12*sex)\n",
    "    lp_s = (params.sel_intercept + params.sel_ses*ses_star\n",
    "            + params.sel_smoke*smoke\n",
    "            + params.sel_bmi*(bmi-25)\n",
    "            + params.sel_age*standardize(age)\n",
    "            + params.sel_risk_score*risk_score)\n",
    "    p_s = logistic(lp_s)\n",
    "    s = rng.binomial(1, p_s, n)\n",
    "\n",
    "    df = pd.DataFrame({\n",
    "        \"age\": age,\n",
    "        \"sex\": sex,\n",
    "        \"pc1\": pc1,\n",
    "        \"ses_star\": ses_star,\n",
    "        \"ses_obs\": ses_obs,\n",
    "        \"ses_quintile\": ses_quintile,\n",
    "        \"bmi\": bmi,\n",
    "        \"sbp\": sbp,\n",
    "        \"smoke\": smoke,\n",
    "        \"y\": y,\n",
    "        \"s\": s,\n",
    "        \"p_s\": p_s,\n",
    "        \"p_y\": p_y\n",
    "    })\n",
    "    return df\n",
    "\n",
    "def sample_biobank(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Extract the biobank sample from population data based on selection indicator.\n",
    "\n",
    "    Filters the population dataset to include only individuals who would\n",
    "    participate in a biobank study (s=1), creating a selected sample that\n",
    "    exhibits systematic bias relative to the target population.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pd.DataFrame\n",
    "        Population dataset containing selection indicator 's'.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        Biobank sample containing only participants (s=1).\n",
    "        Typically 5-15% of the original population size.\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    The biobank sample will exhibit:\n",
    "    - Higher mean SES (selection bias)\n",
    "    - Lower disease prevalence (healthy volunteer bias)\n",
    "    - Different covariate distributions\n",
    "    - Potential collider bias when conditioning on selection\n",
    "\n",
    "    This function simulates the real-world scenario where biobank participants\n",
    "    are not representative of the general population, creating challenges for\n",
    "    causal inference and generalizability.\n",
    "\n",
    "    Examples\n",
    "    --------\n",
    "    >>> pop_data = simulate_population(DGMParams(n=100000))\n",
    "    >>> biobank_data = sample_biobank(pop_data)\n",
    "    >>> print(f\"Selection ratio: {len(biobank_data)/len(pop_data):.1%}\")\n",
    "    >>> print(f\"SES bias: {biobank_data['ses_star'].mean():.2f} vs {pop_data['ses_star'].mean():.2f}\")\n",
    "    \"\"\"\n",
    "    return df.loc[df[\"s\"]==1].copy()\n",
    "\n",
    "# -----------------\n",
    "# Analytic models\n",
    "# -----------------\n",
    "\n",
    "def fit_logit(formula: str, data: pd.DataFrame, weights: Optional[np.ndarray] = None) -> Any:\n",
    "    \"\"\"\n",
    "    Fit a logistic regression model using statsmodels formula interface.\n",
    "\n",
    "    Convenience wrapper for fitting binary logistic regression models with\n",
    "    optional frequency weights, commonly used in epidemiological analyses.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    formula : str\n",
    "        Model formula in patsy/R syntax (e.g., 'y ~ x1 + x2 + bs(x3, df=5)').\n",
    "        Supports transformations, interactions, and spline terms.\n",
    "    data : pd.DataFrame\n",
    "        Dataset containing variables referenced in the formula.\n",
    "    weights : array-like, optional\n",
    "        Frequency weights for weighted logistic regression. Default is None.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    fitted model object\n",
    "        Fitted logistic regression results object with methods for prediction,\n",
    "        summary statistics, and model diagnostics.\n",
    "\n",
    "    Examples\n",
    "    --------\n",
    "    >>> # Simple logistic regression\n",
    "    >>> results = fit_logit('y ~ x1 + x2', data)\n",
    "    >>> \n",
    "    >>> # With spline terms\n",
    "    >>> results = fit_logit('y ~ bs(ses, df=5) + age + sex', data)\n",
    "    >>> \n",
    "    >>> # With weights\n",
    "    >>> results = fit_logit('y ~ x1 + x2', data, weights=sample_weights)\n",
    "    \"\"\"\n",
    "    model = sm.GLM.from_formula(formula=formula, data=data, family=sm.families.Binomial(), freq_weights=weights)\n",
    "    res = model.fit()\n",
    "    return res\n",
    "\n",
    "def null_llf(y: np.ndarray) -> float:\n",
    "    \"\"\"\n",
    "    Calculate log-likelihood of the null (intercept-only) model for binary outcomes.\n",
    "\n",
    "    Computes the maximum likelihood under the null hypothesis that all observations\n",
    "    have the same probability of success, estimated as the sample proportion.\n",
    "    This serves as a baseline for calculating pseudo-R² measures.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    y : array-like\n",
    "        Binary outcome variable (0s and 1s).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        Log-likelihood of the null model: LL₀ = Σᵢ [yᵢlog(p̂) + (1-yᵢ)log(1-p̂)]\n",
    "        where p̂ is the sample proportion of successes.\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    The null model probability is clipped to [1e-6, 1-1e-6] to avoid numerical\n",
    "    issues with log(0) when all outcomes are 0 or 1.\n",
    "\n",
    "    This function is essential for computing McFadden's pseudo-R² and related\n",
    "    goodness-of-fit measures for logistic regression models.\n",
    "\n",
    "    Examples\n",
    "    --------\n",
    "    >>> y = np.array([0, 1, 0, 1, 1])\n",
    "    >>> ll_null = null_llf(y)\n",
    "    >>> print(f\"Null log-likelihood: {ll_null:.3f}\")\n",
    "    \"\"\"\n",
    "    p = np.clip(np.mean(y), 1e-6, 1-1e-6)\n",
    "    ll = np.sum(y*np.log(p) + (1-y)*np.log(1-p))\n",
    "    return float(ll)\n",
    "\n",
    "def g_compute_dose_response(model: Any, data: pd.DataFrame, ses_var: str, a_grid: np.ndarray) -> Tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Estimate m(a) = E[Y | do(SES= a)] by setting SES variable to a and predicting with the fitted model,\n",
    "    averaging over the empirical distribution of observed confounders in `data`.\n",
    "    Note: This treats `ses_var` as the manipulable exposure in the fitted model (could be SES* oracle or SES_obs proxy).\n",
    "    \"\"\"\n",
    "    base = data.copy()\n",
    "    means = []\n",
    "    for a in a_grid:\n",
    "        tmp = base.copy()\n",
    "        tmp[ses_var] = a\n",
    "        # For splines, the design matrix updates automatically via formula interface.\n",
    "        p = model.predict(tmp)\n",
    "        means.append(np.mean(p))\n",
    "    return a_grid, np.array(means)\n",
    "\n",
    "def true_dose_response(df_population: pd.DataFrame, a_grid: np.ndarray, seed: int=7) -> Tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Compute the true m(a) = E[Y | do(SES*=a)] by re-simulating mediators and outcome\n",
    "    while fixing SES* := a and integrating over exogenous noise and baseline covariates.\n",
    "    \"\"\"\n",
    "    rng = np.random.default_rng(seed)\n",
    "    age = df_population[\"age\"].to_numpy()\n",
    "    sex = df_population[\"sex\"].to_numpy()\n",
    "    pc1 = df_population[\"pc1\"].to_numpy()\n",
    "\n",
    "    means = []\n",
    "    n = len(df_population)\n",
    "    for a in a_grid:\n",
    "        # mediators under intervention\n",
    "        bmi = 27.5 + 1.2*(a - 0.2)**2 + 0.05*(age-60) + 0.6*sex + rng.normal(0, 2.5, n)\n",
    "        lp_smoke = -0.5 - 1.2*a + 0.6*(a < -0.5) + 0.01*(age-60) + 0.2*sex\n",
    "        p_smoke = 1.0 / (1.0 + np.exp(-lp_smoke))\n",
    "        smoke = rng.binomial(1, p_smoke, n)\n",
    "        sbp = 125 - 4*np.log1p(np.exp(a - 0.0)) + 0.12*(age-60) + 3.0*sex + rng.normal(0, 8.0, n)\n",
    "        g_ses = 0.25*a + 0.15*(a < -0.8)\n",
    "        lp_y = (-4.1 + g_ses\n",
    "                + 0.06*(sbp-120) + 0.08*(bmi-25) + 1.0*smoke\n",
    "                + 0.018*(age-60) + 0.12*sex)\n",
    "        p_y = 1.0 / (1.0 + np.exp(-lp_y))\n",
    "        means.append(np.mean(p_y))\n",
    "    return a_grid, np.array(means)\n",
    "\n",
    "def causal_R2_from_curve(m_a: np.ndarray, y: np.ndarray) -> float:\n",
    "    \"\"\"\n",
    "    Causal R^2 (risk scale): Var_a( m(a) ) / Var(Y), where a ~ empirical SES distribution.\n",
    "    Here we approximate Var_a(m(a)) by taking the variance across m(a) evaluated over\n",
    "    SES grid weighted equally; you can reweight by SES density if desired.\n",
    "    \"\"\"\n",
    "    var_y = np.var(y, ddof=0)\n",
    "    var_ma = np.var(m_a, ddof=0)\n",
    "    return float(var_ma / var_y)\n",
    "\n",
    "# -----------------\n",
    "# Demo / single-run analysis\n",
    "# -----------------\n",
    "\n",
    "def run_demo(n_pop: int = 200_000, seed: int = 42) -> Tuple[Dict[str, float], pd.DataFrame, pd.DataFrame, np.ndarray, np.ndarray, np.ndarray, np.ndarray, np.ndarray, Any, Any, Any, Any]:\n",
    "    \"\"\"\n",
    "    Execute complete simulation study comparing SES-health causal inference methods.\n",
    "\n",
    "    Runs a comprehensive analysis comparing traditional epidemiological approaches\n",
    "    with modern causal inference methods for estimating socioeconomic effects on\n",
    "    health outcomes in the presence of selection bias and measurement error.\n",
    "\n",
    "    This function implements the full simulation pipeline:\n",
    "    1. Generate population with complex SES-health relationships\n",
    "    2. Apply biobank selection bias\n",
    "    3. Fit multiple analytical models\n",
    "    4. Estimate causal dose-response curves\n",
    "    5. Compute performance metrics and decompositions\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    n_pop : int, default=200_000\n",
    "        Population size for simulation. Larger values provide more stable\n",
    "        estimates but increase computational time.\n",
    "    seed : int, default=42\n",
    "        Random seed for reproducible results.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Tuple containing:\n",
    "        results : Dict[str, float]\n",
    "            Performance metrics including:\n",
    "            - Sample sizes and prevalence rates\n",
    "            - McFadden and Tjur R² for different models\n",
    "            - Causal R² estimates (true, oracle, proxy)\n",
    "            - Shapley value decomposition\n",
    "\n",
    "        pop : pd.DataFrame\n",
    "            Full population dataset\n",
    "\n",
    "        biobank : pd.DataFrame  \n",
    "            Selected biobank sample\n",
    "\n",
    "        a_grid : np.ndarray\n",
    "            SES* intervention grid\n",
    "\n",
    "        a_grid_obs : np.ndarray\n",
    "            SES_obs intervention grid\n",
    "\n",
    "        m_true : np.ndarray\n",
    "            True causal dose-response curve\n",
    "\n",
    "        m_hat_star : np.ndarray\n",
    "            Oracle G-computation estimates (using SES*)\n",
    "\n",
    "        m_hat_obs : np.ndarray\n",
    "            Proxy G-computation estimates (using SES_obs)\n",
    "\n",
    "        res_lin, res_over, res_spline_obs, res_spline_star : fitted model objects\n",
    "            Fitted regression models for further analysis\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    The analysis compares:\n",
    "\n",
    "    **Traditional Approaches (Problematic):**\n",
    "    - Linear quintile models (mis-specification)\n",
    "    - Over-adjusted models including mediators (collider bias)\n",
    "\n",
    "    **Modern Approaches (Preferred):**\n",
    "    - Flexible spline models capturing non-linearity\n",
    "    - G-computation for causal dose-response curves\n",
    "    - Oracle vs. proxy SES comparisons\n",
    "\n",
    "    **Key Metrics:**\n",
    "    - McFadden's/Tjur's R²: Traditional model fit\n",
    "    - Causal R²: Proportion of variance from SES interventions\n",
    "    - Shapley values: Fair attribution of explanatory power\n",
    "\n",
    "    The simulation demonstrates:\n",
    "    - Bias from selection and measurement error\n",
    "    - Advantages of flexible modeling approaches\n",
    "    - Importance of causal vs. predictive frameworks\n",
    "\n",
    "    Examples\n",
    "    --------\n",
    "    >>> # Run basic demo\n",
    "    >>> results, pop, biobank, *curves = run_demo(n_pop=50000)\n",
    "    >>> print(f\"True causal R²: {results['causal_R2_true']:.3f}\")\n",
    "    >>> print(f\"Biobank bias: {results['mean_y_population']:.3f} vs {results['mean_y_biobank']:.3f}\")\n",
    "    >>> \n",
    "    >>> # Custom parameters\n",
    "    >>> results, *_ = run_demo(n_pop=100000, seed=456)\n",
    "    >>> \n",
    "    >>> # Extract dose-response curves for plotting\n",
    "    >>> _, _, _, a_grid, a_grid_obs, m_true, m_oracle, m_proxy, *_ = run_demo()\n",
    "    >>> plt.plot(a_grid, m_true, label='True curve')\n",
    "    >>> plt.plot(a_grid, m_oracle, label='Oracle estimate')\n",
    "    >>> plt.plot(a_grid_obs, m_proxy, label='Proxy estimate')\n",
    "    \"\"\"\n",
    "    params = DGMParams(n=n_pop, seed=seed)\n",
    "    pop = simulate_population(params)\n",
    "    biobank = pop.loc[pop[\"s\"]==1].copy()\n",
    "\n",
    "    # SES grids\n",
    "    a_grid = np.linspace(np.percentile(pop[\"ses_star\"], 2),\n",
    "                         np.percentile(pop[\"ses_star\"], 98), 30)\n",
    "    a_grid_obs = np.linspace(np.percentile(pop[\"ses_obs\"], 2),\n",
    "                             np.percentile(pop[\"ses_obs\"], 98), 30)\n",
    "\n",
    "    # True curve (population, oracle)\n",
    "    _, m_true = true_dose_response(pop, a_grid)\n",
    "\n",
    "    # A) Mis-specified models (selected sample)\n",
    "    # Linear SES quintile (treated numeric) + C\n",
    "    formula_lin = \"y ~ ses_quintile + age + sex + pc1\"\n",
    "    res_lin = sm.GLM.from_formula(formula_lin, data=biobank, family=sm.families.Binomial()).fit()\n",
    "    p_lin = res_lin.predict(biobank)\n",
    "    r2_lin_mcf = mc_fadden_r2(res_lin.llf, null_llf(biobank[\"y\"].to_numpy()))\n",
    "    r2_lin_tjur = tjur_r2(biobank[\"y\"], p_lin)\n",
    "\n",
    "    # Over-adjustment (include mediators; typical risk-factor model)\n",
    "    formula_over = \"y ~ ses_quintile + age + sex + pc1 + bmi + sbp + smoke\"\n",
    "    res_over = sm.GLM.from_formula(formula_over, data=biobank, family=sm.families.Binomial()).fit()\n",
    "    p_over = res_over.predict(biobank)\n",
    "    r2_over_mcf = mc_fadden_r2(res_over.llf, null_llf(biobank[\"y\"].to_numpy()))\n",
    "\n",
    "    # B) Flexible spline on observed SES\n",
    "    biobank = biobank.assign(\n",
    "        ses_obs_spline = biobank[\"ses_obs\"]  # keep name for formula\n",
    "    )\n",
    "    formula_spline_obs = \"y ~ bs(ses_obs_spline, df=5) + age + sex + pc1\"\n",
    "    res_spline_obs = sm.GLM.from_formula(formula_spline_obs, data=biobank, family=sm.families.Binomial()).fit()\n",
    "\n",
    "    # (Oracle) Flexible spline on SES*\n",
    "    biobank = biobank.assign(\n",
    "        ses_star_spline = biobank[\"ses_star\"]\n",
    "    )\n",
    "    formula_spline_star = \"y ~ bs(ses_star_spline, df=5) + age + sex + pc1\"\n",
    "    res_spline_star = sm.GLM.from_formula(formula_spline_star, data=biobank, family=sm.families.Binomial()).fit()\n",
    "\n",
    "    # C) G-computation curves (selected sample)\n",
    "    _, m_hat_obs = g_compute_dose_response(res_spline_obs, biobank, \"ses_obs_spline\", a_grid_obs)\n",
    "    _, m_hat_star = g_compute_dose_response(res_spline_star, biobank, \"ses_star_spline\", a_grid)\n",
    "\n",
    "    # Causal R^2 (approx) using curves; compare to observed Var(Y)\n",
    "    r2_causal_true = causal_R2_from_curve(m_true, pop[\"y\"].to_numpy())\n",
    "    r2_causal_oracle = causal_R2_from_curve(m_hat_star, biobank[\"y\"].to_numpy())\n",
    "    r2_causal_proxy = causal_R2_from_curve(m_hat_obs, biobank[\"y\"].to_numpy())\n",
    "\n",
    "    # Simple two-group Shapley (SES vs others) on selected sample\n",
    "    # Group 1: SES* spline (oracle); Group 2: C = age, sex, pc1\n",
    "    llf_null = null_llf(biobank[\"y\"].to_numpy())\n",
    "    llf_g1 = sm.GLM.from_formula(\"y ~ bs(ses_star_spline, df=5)\", data=biobank, family=sm.families.Binomial()).fit().llf\n",
    "    llf_g2 = sm.GLM.from_formula(\"y ~ age + sex + pc1\", data=biobank, family=sm.families.Binomial()).fit().llf\n",
    "    llf_both = res_spline_star.llf\n",
    "    shap = shapley_two_groups_r2(llf_null, llf_g1, llf_g2, llf_both)\n",
    "\n",
    "    out = {\n",
    "        \"n_population\": int(len(pop)),\n",
    "        \"n_biobank\": int(len(biobank)),\n",
    "        \"mean_y_population\": float(pop[\"y\"].mean()),\n",
    "        \"mean_y_biobank\": float(biobank[\"y\"].mean()),\n",
    "        \"mcFadden_R2_linear_quintile\": float(r2_lin_mcf),\n",
    "        \"Tjur_R2_linear_quintile\": float(r2_lin_tjur),\n",
    "        \"mcFadden_R2_overadjusted\": float(r2_over_mcf),\n",
    "        \"causal_R2_true\": float(r2_causal_true),\n",
    "        \"causal_R2_oracle_SESstar\": float(r2_causal_oracle),\n",
    "        \"causal_R2_proxy_SESobs\": float(r2_causal_proxy),\n",
    "        \"Shapley_SESstar_share\": shap[\"G1_share\"],\n",
    "        \"Shapley_C_share\": shap[\"G2_share\"],\n",
    "        \"Shapley_R2_total\": shap[\"R2_total\"],\n",
    "    }\n",
    "    return out, pop, biobank, a_grid, a_grid_obs, m_true, m_hat_star, m_hat_obs, res_lin, res_over, res_spline_obs, res_spline_star\n",
    "\n",
    "\n",
    "# -----------------\n",
    "# Main execution\n",
    "# -----------------\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \"\"\"\n",
    "    Run the SES simulation demo when script is executed directly.\n",
    "    \"\"\"\n",
    "    print(\"SES Simulation Scaffold - Running Demo Analysis\")\n",
    "    print(\"=\" * 50)\n",
    "\n",
    "    # Run the simulation\n",
    "    print(\"Generating population and running analysis...\")\n",
    "    results, pop, biobank, a_grid, a_grid_obs, m_true, m_hat_star, m_hat_obs, *models = run_demo(\n",
    "        n_pop=50_000,  # Smaller sample for faster demo\n",
    "        seed=42\n",
    "    )\n",
    "\n",
    "    print(\"\\n\" + \"Results Summary\" + \"\\n\" + \"-\" * 20)\n",
    "\n",
    "    # Sample sizes and basic stats\n",
    "    print(f\"Population size: {results['n_population']:,}\")\n",
    "    print(f\"Biobank sample: {results['n_biobank']:,} ({results['n_biobank']/results['n_population']:.1%})\")\n",
    "    print(f\"Population disease prevalence: {results['mean_y_population']:.1%}\")\n",
    "    print(f\"Biobank disease prevalence: {results['mean_y_biobank']:.1%}\")\n",
    "\n",
    "    # Model performance comparison\n",
    "    print(f\"\\nModel Performance (McFadden R²):\")\n",
    "    print(f\"  Linear quintile model: {results['mcFadden_R2_linear_quintile']:.3f}\")\n",
    "    print(f\"  Over-adjusted model: {results['mcFadden_R2_overadjusted']:.3f}\")\n",
    "    print(f\"  Tjur R² (linear model): {results['Tjur_R2_linear_quintile']:.3f}\")\n",
    "\n",
    "    # Causal R² estimates\n",
    "    print(f\"\\nCausal R² Estimates:\")\n",
    "    print(f\"  True causal R²: {results['causal_R2_true']:.3f}\")\n",
    "    print(f\"  Oracle estimate (SES*): {results['causal_R2_oracle_SESstar']:.3f}\")\n",
    "    print(f\"  Proxy estimate (SES_obs): {results['causal_R2_proxy_SESobs']:.3f}\")\n",
    "\n",
    "    # Shapley decomposition\n",
    "    print(f\"\\nShapley Value Decomposition:\")\n",
    "    print(f\"  SES* contribution: {results['Shapley_SESstar_share']:.3f}\")\n",
    "    print(f\"  Other covariates: {results['Shapley_C_share']:.3f}\")\n",
    "    print(f\"  Total R²: {results['Shapley_R2_total']:.3f}\")\n",
    "\n",
    "    # Interpretation\n",
    "    print(f\"\\n\" + \"Key Insights\" + \"\\n\" + \"-\" * 15)\n",
    "\n",
    "    # Selection bias\n",
    "    bias_direction = \"healthier\" if results['mean_y_biobank'] < results['mean_y_population'] else \"sicker\"\n",
    "    bias_magnitude = abs(results['mean_y_biobank'] - results['mean_y_population']) / results['mean_y_population']\n",
    "    print(f\"• Biobank shows {bias_magnitude:.1%} {bias_direction} population (healthy volunteer bias)\")\n",
    "\n",
    "    # Causal vs predictive\n",
    "    oracle_vs_true = results['causal_R2_oracle_SESstar'] / results['causal_R2_true']\n",
    "    proxy_vs_true = results['causal_R2_proxy_SESobs'] / results['causal_R2_true']\n",
    "    print(f\"• Oracle method captures {oracle_vs_true:.1%} of true causal effect\")\n",
    "    print(f\"• Proxy method captures {proxy_vs_true:.1%} of true causal effect\")\n",
    "\n",
    "    # SES importance\n",
    "    ses_importance = results['Shapley_SESstar_share'] / results['Shapley_R2_total']\n",
    "    print(f\"• SES accounts for {ses_importance:.1%} of total explainable variance\")\n",
    "\n",
    "    print(f\"\\n\" + \"Methodological Lessons\" + \"\\n\" + \"-\" * 25)\n",
    "    print(\"• Selection bias reduces disease prevalence in biobank samples\")\n",
    "    print(\"• Measurement error in SES attenuates causal effect estimates\") \n",
    "    print(\"• Flexible modeling approaches better capture non-linear relationships\")\n",
    "    print(\"• G-computation provides interpretable causal dose-response curves\")\n",
    "\n",
    "    print(f\"\\nDemo completed successfully!\")\n",
    "    print(\"Tip: Use the returned objects for further analysis and visualization.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write a module copy for external tests (robust to missing 'sim_code' var)\n",
    "sim_module_path = os.path.join(ART_DIR, \"ses_sim_module.py\")\n",
    "\n",
    "# Try 1: if a variable 'sim_code' exists (not required), use it\n",
    "_sim_code = None\n",
    "try:\n",
    "    _sim_code = sim_code  # noqa: F821\n",
    "except Exception:\n",
    "    _sim_code = None\n",
    "\n",
    "# Try 2: read from a local file 'ses_sim_new.py' (repo root)\n",
    "if _sim_code is None:\n",
    "    try:\n",
    "        with open(\"ses_sim_new.py\", \"r\", encoding=\"utf-8\") as _f:\n",
    "            _sim_code = _f.read()\n",
    "    except Exception:\n",
    "        _sim_code = None\n",
    "\n",
    "# Write out if we have source; otherwise warn (pytest falls back to ses_sim_new.py)\n",
    "if _sim_code is not None:\n",
    "    with open(sim_module_path, \"w\", encoding=\"utf-8\") as _f:\n",
    "        _f.write(_sim_code)\n",
    "    print(\"Wrote simulation module to:\", sim_module_path)\n",
    "else:\n",
    "    print(\"Warning: could not capture simulation source. Tests will import 'ses_sim_new.py' from repo root.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run simulation & save artifacts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "results, pop, biobank, a_grid, a_grid_obs, m_true, m_hat_star, m_hat_obs, *_ = run_demo(n_pop=N_POP, seed=SEED)\n",
    "\n",
    "pd.DataFrame([results]).to_csv(f\"{ART_DIR}/simulation_metrics.csv\", index=False)\n",
    "\n",
    "# Figure styling (no custom colors; grid + bigger fonts)\n",
    "plt.figure(figsize=(7,5), dpi=150)\n",
    "plt.grid(alpha=0.3)\n",
    "plt.plot(a_grid, m_true, label=\"True m(a)\")\n",
    "plt.plot(a_grid, m_hat_star, linestyle=\"--\", label=\"G-comp (oracle SES*)\")\n",
    "plt.plot(a_grid_obs, m_hat_obs, linestyle=\":\", label=\"G-comp (proxy SES_obs)\")\n",
    "plt.xlabel(\"SES value (grid)\", fontsize=11); plt.ylabel(\"Risk E[Y | do(SES=a)]\", fontsize=11)\n",
    "plt.title(\"Simulation: Dose–response curves\", fontsize=12)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"{ART_DIR}/simulation_dose_response.png\")\n",
    "print(\"Saved:\", f\"{ART_DIR}/simulation_dose_response.png\")\n",
    "results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inline unit tests (simulation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Lightweight invariants for reproducibility checks\n",
    "import math\n",
    "\n",
    "def approx(x, lo, hi, name):\n",
    "    assert (lo <= x <= hi), f\"{name} out of expected range: {x} not in [{lo},{hi}]\"\n",
    "\n",
    "# Basic structure\n",
    "assert isinstance(results, dict) and \"causal_R2_true\" in results\n",
    "\n",
    "# Probabilities & sizes\n",
    "approx(pop['y'].mean(), 0.01, 0.25, \"Population prevalence\")\n",
    "approx(biobank['y'].mean(), 0.005, 0.20, \"Selected prevalence\")\n",
    "assert len(pop) >= N_POP*0.9   # after clipping bounds\n",
    "assert len(biobank) > 0\n",
    "\n",
    "# Curves monotone-ish (expected: risk declines with higher SES on avg)\n",
    "assert np.nanmean(np.diff(m_true)) < 0.0, \"True m(a) not decreasing on average\"\n",
    "\n",
    "# Pseudo R^2 non-negative\n",
    "for k in ['mcFadden_R2_linear_quintile','mcFadden_R2_overadjusted']:\n",
    "    assert results[k] >= 0\n",
    "\n",
    "# Causal R^2 bounded\n",
    "for k in ['causal_R2_true','causal_R2_oracle_SESstar','causal_R2_proxy_SESobs']:\n",
    "    approx(results[k], 0.0, 0.10, k)\n",
    "\n",
    "print(\"Inline tests passed.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results (compact, auto-filled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from pathlib import Path\n",
    "m = pd.read_csv(f\"{ART_DIR}/simulation_metrics.csv\").iloc[0].to_dict()\n",
    "print(f\"\"\"\n",
    "Population size: {int(m.get('n_population', len(pop))):,}\n",
    "Selected (biobank-like) size: {int(m.get('n_biobank', len(biobank))):,}\n",
    "Population prevalence: {pop['y'].mean():.2%}; Selected prevalence: {biobank['y'].mean():.2%}\n",
    "\n",
    "Model fit (selected sample):\n",
    "  McFadden R^2 — linear SES quintile: {m.get('mcFadden_R2_linear_quintile', float('nan')):.3f}\n",
    "  McFadden R^2 — over-adjusted:        {m.get('mcFadden_R2_overadjusted', float('nan')):.3f}\n",
    "\n",
    "Causal variance share (risk scale):\n",
    "  True population causal R^2:          {m.get('causal_R2_true', float('nan')):.4f}\n",
    "  Oracle (SES*) causal R^2 (selected): {m.get('causal_R2_oracle_SESstar', float('nan')):.4f}\n",
    "  Proxy (SES_obs) causal R^2 (selected): {m.get('causal_R2_proxy_SESobs', float('nan')):.4f}\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part B — NHANES scaffold (optional)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# NHANES scaffold — runs only if you set NHANES_BASE_DIR to local XPTs\n",
    "from dataclasses import dataclass\n",
    "from typing import List\n",
    "import os, glob, numpy as np, pandas as pd, statsmodels.api as sm\n",
    "from patsy import bs\n",
    "\n",
    "@dataclass\n",
    "class NHANESConfig:\n",
    "    base_dir: str\n",
    "    cycles: List[str]\n",
    "    use_exam_weights: bool = True\n",
    "\n",
    "def logistic(x): return 1/(1+np.exp(-x))\n",
    "\n",
    "def find_xpt(pats, base_dir):\n",
    "    out=[]; \n",
    "    import glob, os\n",
    "    for p in pats: out += glob.glob(os.path.join(base_dir, \"**\", p), recursive=True)\n",
    "    return sorted(out)\n",
    "\n",
    "def read_xpt(p): return pd.read_sas(p, format=\"xport\", encoding=\"latin-1\")\n",
    "\n",
    "def pick_first(df, names):\n",
    "    for n in names:\n",
    "        if n in df.columns: return df[n]\n",
    "    return pd.Series([np.nan]*len(df))\n",
    "\n",
    "def average_bp(df, cols):\n",
    "    cols=[c for c in cols if c in df.columns]\n",
    "    return df[cols].mean(axis=1, skipna=True) if cols else pd.Series([np.nan]*len(df))\n",
    "\n",
    "def load_demographics(cfg):\n",
    "    ps = find_xpt([f\"DEMO_{c}.XPT\" for c in cfg.cycles]+[f\"DEMO_{c}.xpt\" for c in cfg.cycles], cfg.base_dir)\n",
    "    if not ps: raise FileNotFoundError(\"No DEMO files found\")\n",
    "    frames=[]\n",
    "    for p in ps:\n",
    "        cyc=p.split(\"_\")[-1].split(\".\")[0]\n",
    "        d=read_xpt(p); d[\"cycle\"]=cyc; frames.append(d)\n",
    "    d=pd.concat(frames, ignore_index=True, sort=False)\n",
    "    return pd.DataFrame({\n",
    "        \"SEQN\":d[\"SEQN\"],\"cycle\":d[\"cycle\"],\n",
    "        \"age\":d[\"RIDAGEYR\"],\"sex\":d[\"RIAGENDR\"],\n",
    "        \"race_eth\": pick_first(d,[\"RIDRETH3\",\"RIDRETH1\"]),\n",
    "        \"pir\": d[\"INDFMPIR\"], \"educ\": d.get(\"DMDEDUC2\", pd.Series([np.nan]*len(d))),\n",
    "        \"strata\": d[\"SDMVSTRA\"], \"psu\": d[\"SDMVPSU\"],\n",
    "        \"wt_int_2yr\": d.get(\"WTINT2YR\", pd.Series([np.nan]*len(d))),\n",
    "        \"wt_mec_2yr\": d.get(\"WTMEC2YR\", pd.Series([np.nan]*len(d))),\n",
    "        \"wt_mec_4yr\": d.get(\"WTMEC4YR\", pd.Series([np.nan]*len(d))),\n",
    "    })\n",
    "\n",
    "def load_exam_bp_bmi(cfg):\n",
    "    bpx=find_xpt([f\"BPX_{c}.XPT\" for c in cfg.cycles]+[f\"BPX_{c}.xpt\" for c in cfg.cycles], cfg.base_dir)\n",
    "    bmx=find_xpt([f\"BMX_{c}.XPT\" for c in cfg.cycles]+[f\"BMX_{c}.xpt\" for c in cfg.cycles], cfg.base_dir)\n",
    "    frames=[]\n",
    "    for p in bpx:\n",
    "        cyc=p.split(\"_\")[-1].split(\".\")[0]; d=read_xpt(p); d[\"cycle\"]=cyc\n",
    "        frames.append(pd.DataFrame({\"SEQN\":d[\"SEQN\"],\"cycle\":cyc,\"sbp\":average_bp(d,[\"BPXSY1\",\"BPXSY2\",\"BPXSY3\",\"BPXSY4\"])}))\n",
    "    bpx_df=pd.concat(frames, ignore_index=True, sort=False) if frames else pd.DataFrame(columns=[\"SEQN\",\"cycle\",\"sbp\"])\n",
    "    frames=[]\n",
    "    for p in bmx:\n",
    "        cyc=p.split(\"_\")[-1].split(\".\")[0]; d=read_xpt(p); d[\"cycle\"]=cyc\n",
    "        frames.append(pd.DataFrame({\"SEQN\":d[\"SEQN\"],\"cycle\":cyc,\"bmi\":d.get(\"BMXBMI\", np.nan)}))\n",
    "    bmx_df=pd.concat(frames, ignore_index=True, sort=False) if frames else pd.DataFrame(columns=[\"SEQN\",\"cycle\",\"bmi\"])\n",
    "    return bpx_df.merge(bmx_df, on=[\"SEQN\",\"cycle\"], how=\"outer\")\n",
    "\n",
    "def load_smoking_mcq(cfg):\n",
    "    mcq=find_xpt([f\"MCQ_{c}.XPT\" for c in cfg.cycles]+[f\"MCQ_{c}.xpt\" for c in cfg.cycles], cfg.base_dir)\n",
    "    smq=find_xpt([f\"SMQ_{c}.XPT\" for c in cfg.cycles]+[f\"SMQ_{c}.xpt\" for c in cfg.cycles], cfg.base_dir)\n",
    "    frames=[]\n",
    "    for p in mcq:\n",
    "        cyc=p.split(\"_\")[-1].split(\".\")[0]; d=read_xpt(p); d[\"cycle\"]=cyc\n",
    "        any_cvd=((d.get(\"MCQ160B\",0)==1)|(d.get(\"MCQ160C\",0)==1)|(d.get(\"MCQ160D\",0)==1)|\n",
    "                 (d.get(\"MCQ160E\",0)==1)|(d.get(\"MCQ160F\",0)==1)).astype(float)\n",
    "        frames.append(pd.DataFrame({\"SEQN\":d[\"SEQN\"],\"cycle\":cyc,\"cvd\":any_cvd}))\n",
    "    mcq_df=pd.concat(frames, ignore_index=True, sort=False) if frames else pd.DataFrame(columns=[\"SEQN\",\"cycle\",\"cvd\"])\n",
    "    frames=[]\n",
    "    for p in smq:\n",
    "        cyc=p.split(\"_\")[-1].split(\".\")[0]; d=read_xpt(p); d[\"cycle\"]=cyc\n",
    "        ever100=(d.get(\"SMQ020\",np.nan)==1).astype(float); now=d.get(\"SMQ040\",np.nan)\n",
    "        current=np.where(np.isin(now,[1,2]),1.0,np.where(now==3,0.0,np.nan))\n",
    "        frames.append(pd.DataFrame({\"SEQN\":d[\"SEQN\"],\"cycle\":cyc,\"smoke\":np.where(ever100==1,current,np.nan)}))\n",
    "    smq_df=pd.concat(frames, ignore_index=True, sort=False) if frames else pd.DataFrame(columns=[\"SEQN\",\"cycle\",\"smoke\"])\n",
    "    return mcq_df.merge(smq_df, on=[\"SEQN\",\"cycle\"], how=\"outer\")\n",
    "\n",
    "def combined_weight(demo, cycles, use_exam=True):\n",
    "    wt = demo[\"wt_mec_2yr\"] if use_exam else demo[\"wt_int_2yr\"]\n",
    "    k = max(len(cycles),1)\n",
    "    use4 = demo[\"wt_mec_4yr\"].notna()\n",
    "    return pd.Series(np.where(use4, demo[\"wt_mec_4yr\"], wt/k), index=demo.index, name=\"wt_combined\")\n",
    "\n",
    "def build_analytic(cfg):\n",
    "    demo=load_demographics(cfg); exam=load_exam_bp_bmi(cfg); oth=load_smoking_mcq(cfg)\n",
    "    df=demo.merge(exam,on=[\"SEQN\",\"cycle\"],how=\"left\").merge(oth,on=[\"SEQN\",\"cycle\"],how=\"left\")\n",
    "    df[\"male\"]=(df[\"sex\"]==1).astype(float)\n",
    "    df[\"wt_combined\"]=combined_weight(df, cfg.cycles, use_exam=cfg.use_exam_weights)\n",
    "    return df[df[\"age\"]>=20].copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if NHANES_BASE_DIR and os.path.isdir(NHANES_BASE_DIR):\n",
    "    try:\n",
    "        cfg = NHANESConfig(base_dir=NHANES_BASE_DIR, cycles=NHANES_CYCLES)\n",
    "        print(\"NHANES base:\", NHANES_BASE_DIR, \"cycles:\", NHANES_CYCLES)\n",
    "        # Full pipeline would go here (left minimal to avoid heavy compute without data)\n",
    "        print(\"NHANES: ready (data found).\")\n",
    "    except Exception as e:\n",
    "        print(\"NHANES scaffold error:\", e)\n",
    "else:\n",
    "    print(\"NHANES: skipped (no local XPT path set).\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Session info & code hashes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels, patsy, matplotlib, hashlib, json, os, platform, sys\n",
    "def ver(m):\n",
    "    try: return m.__version__\n",
    "    except: return \"NA\"\n",
    "\n",
    "info = {\n",
    "    \"python\": sys.version,\n",
    "    \"platform\": platform.platform(),\n",
    "    \"numpy\": np.__version__,\n",
    "    \"pandas\": pd.__version__,\n",
    "    \"statsmodels\": ver(statsmodels),\n",
    "    \"patsy\": ver(patsy),\n",
    "    \"matplotlib\": ver(matplotlib),\n",
    "}\n",
    "\n",
    "# Robust hashing of simulation source:\n",
    "# 1) try 'sim_code' if present;\n",
    "# 2) else read artifacts/ses_sim_module.py (written earlier);\n",
    "# 3) else read ses_sim_new.py from repo root;\n",
    "# 4) else mark NA.\n",
    "_sim_src = None\n",
    "try:\n",
    "    _sim_src = sim_code  # may be undefined\n",
    "except Exception:\n",
    "    _sim_src = None\n",
    "\n",
    "if _sim_src is None:\n",
    "    for candidate in [os.path.join(ART_DIR, \"ses_sim_module.py\"), \"ses_sim_new.py\"]:\n",
    "        if os.path.exists(candidate):\n",
    "            with open(candidate, \"r\", encoding=\"utf-8\") as fh:\n",
    "                _sim_src = fh.read()\n",
    "            break\n",
    "\n",
    "info[\"ses_sim_new_sha256\"] = hashlib.sha256(_sim_src.encode(\"utf-8\")).hexdigest() if _sim_src is not None else \"NA\"\n",
    "\n",
    "with open(f\"{ART_DIR}/session_info.json\",\"w\") as f:\n",
    "    json.dump(info, f, indent=2)\n",
    "\n",
    "info\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
